{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(314159) # set random seed\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.loader\n",
    "\n",
    "import wandb\n",
    "\n",
    "import models\n",
    "from data_utils import read_data, create_data\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/final_data/'\n",
    "\n",
    "model_creator_dict = {'SGConv': models.create_SGConv_GNN,\n",
    "                      'GraphSAGE': models.create_GraphSAGE_GNN,\n",
    "                      'TAG': models.create_TAG_GNN,\n",
    "                      'ClusterGCN': models.create_clusterGCN_GNN,\n",
    "                      'MLP': models.create_MLP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dataset, edge_list, labels = read_data(base_path=base_path, graph_used='know', feats_type='nodeonly', label_thres='0,02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_features = len(node_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_name = 'train_gnn_model.ipynb'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = notebook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn import metrics\n",
    "\n",
    "def run_trials(create_model, start_trial=0, end_trial=100, n_epochs=500, log=False, log_project=None):\n",
    "\n",
    "    if log:\n",
    "        # dt_string = str(datetime.datetime.today()).replace(' ', '_')\n",
    "        if log_project is None:\n",
    "            print('Enter the name of the log project: ')\n",
    "            log_project = input()\n",
    "\n",
    "    # model info\n",
    "    model = create_model()\n",
    "    model_summary = pl.utilities.model_summary.summarize(model, max_depth=4)\n",
    "    model_summary_str = str(model_summary)\n",
    "    num_trainable_params = model_summary.trainable_parameters\n",
    "\n",
    "    print(model_summary_str)\n",
    "\n",
    "    train_reports = []\n",
    "    test_reports = []\n",
    "    roc_data = []\n",
    "\n",
    "    for trial in tqdm(range(start_trial, end_trial + 1)):\n",
    "\n",
    "        print(f'running trial {str(trial)}')\n",
    "        data = create_data(node_dataset, edge_list, labels, f'label_{trial}', test_size=0.2, val_size=0.1)\n",
    "\n",
    "\n",
    "        model = create_model()\n",
    "\n",
    "        if log:\n",
    "            n_zfills = int(np.ceil(np.log10(100)))\n",
    "            log_name = f'{log_project}_trial{str(trial).zfill(n_zfills)}'\n",
    "\n",
    "            logger = WandbLogger(name=log_name, project=log_project, log_model=\"\\all\\\\\", save_dir='wandb_projects')\n",
    "\n",
    "            logger.log_metrics({'model_summary_str': model_summary_str,\n",
    "                                'num_trainable_params': num_trainable_params})\n",
    "            \n",
    "            # log random train-val-test split\n",
    "            logger.log_metrics({'train_mask': data.train_mask, 'val_mask': data.val_mask, 'test_mask': data.test_mask})\n",
    "\n",
    "        else:\n",
    "            logger = False\n",
    "\n",
    "        AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "\n",
    "        data_loader = torch_geometric.loader.DataLoader([data], batch_size=1, num_workers=os.cpu_count())\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "                    callbacks=[ModelCheckpoint(save_weights_only=False, mode=\"max\", monitor='val_acc')],\n",
    "                    gpus=AVAIL_GPUS,\n",
    "                    max_epochs=n_epochs,\n",
    "                    logger=logger,\n",
    "                    enable_model_summary=False\n",
    "                    # progress_bar_refresh_rate=0,\n",
    "                    )\n",
    "\n",
    "        trainer.fit(model, data_loader, data_loader)\n",
    "\n",
    "        model = models.LitGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "        train_report, test_report = model_utils.evaluate_model(model, data, logger=logger)\n",
    "\n",
    "        train_reports.append(train_report)\n",
    "        test_reports.append(test_report)\n",
    "\n",
    "        model.to(device='cuda')\n",
    "        logits, _, _ = model.forward(data.to(device='cuda'))\n",
    "\n",
    "        preds = logits[data.test_mask][:, 1].cpu().detach().numpy()\n",
    "        y = data.y[data.test_mask].cpu().detach().numpy()\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y, preds)\n",
    "        auc_score = metrics.roc_auc_score(y, preds)\n",
    "\n",
    "        roc_data.append({'fpr': fpr, 'tpr': tpr, 'threholds': thresholds, 'auc': auc_score})\n",
    "\n",
    "        if log:\n",
    "            logger.log_metrics({'auc_test': auc_score, 'fpr_test': fpr, \n",
    "                                'tpr_test': tpr, 'roc_thres': thresholds})\n",
    "\n",
    "        if log:\n",
    "            wandb.save('modeling_gnn.ipynb')\n",
    "            wandb.finish(quiet=True)\n",
    "\n",
    "        del model, data_loader, trainer, data\n",
    "        gc.collect()\n",
    "\n",
    "        print('memory allocated: ', torch.cuda.memory_allocated())\n",
    "        print('memory reserved: ', torch.cuda.memory_reserved())\n",
    "        torch.cuda.empty_cache()\n",
    "        print('\\\\nafter empty_cache:')\n",
    "        print('memory allocated: ', torch.cuda.memory_allocated())\n",
    "        print('memory reserved: ', torch.cuda.memory_reserved())\n",
    "\n",
    "\n",
    "\n",
    "    return train_reports, test_reports, roc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name              | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0  | model             | GNNModel         | 162 K \n",
      "1  | model.convs       | ModuleList       | 145 K \n",
      "2  | model.convs.0     | SGConv           | 13.8 K\n",
      "3  | model.convs.0.lin | Linear           | 13.8 K\n",
      "4  | model.convs.1     | SGConv           | 33.0 K\n",
      "5  | model.convs.1.lin | Linear           | 33.0 K\n",
      "6  | model.convs.2     | SGConv           | 65.8 K\n",
      "7  | model.convs.2.lin | Linear           | 65.8 K\n",
      "8  | model.convs.3     | SGConv           | 32.9 K\n",
      "9  | model.convs.3.lin | Linear           | 32.9 K\n",
      "10 | model.dense1      | Linear           | 16.5 K\n",
      "11 | model.dense_out   | Linear           | 258   \n",
      "12 | loss_module       | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "162 K     Trainable params\n",
      "0         Non-trainable params\n",
      "162 K     Total params\n",
      "0.649     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running trial 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbyle\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "## TRAIN AND EVALUATE MODEL\n",
    "\n",
    "model_name = 'SGConv'\n",
    "create_model = model_creator_dict[model_name]\n",
    "\n",
    "log_project_name = f'{model_name}'\n",
    "\n",
    "# run multiple trials\n",
    "train_reports, test_reports, roc_data = run_trials(lambda: create_model(model_name, num_features, num_classes), start_trial=0, end_trial=0,\n",
    "                                         n_epochs=250, log=False, log_project=log_project_name)\n",
    "\n",
    "# save reports from trials to json\n",
    "model_utils.save_reports(f'project_reports/{log_project_name}_reports', train_reports, test_reports)\n",
    "np.save(f'project_reports/{model_name}_roc', roc_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
